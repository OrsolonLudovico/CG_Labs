---
title: "Preprocessing microbiome data"
author: "Barbara Di Camillo, Marco Cappellato"
output:
  html_document:
    theme: readable
    toc: yes
    toc_depth: 3
    number_sections: true
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

library(SingleCellExperiment)
load("sce_lab.RData")
sce
assays(sce)

#Note: thie following just adds a column to the colData assay, IT DOESN'T ADD A NEW ASSAY, IT'S KINDA DIFFICULT TO DO SO
#library(scDblFinder)
#scores <- computeDoubletDensity(sce)
#sce$DoubletScore <- scores 
```

```{r}
metadata(sce)$metaArg <- "This is a new field in the metadata assay"
metadata(sce)$metaArg
```
#*Droplets*
```{r}
library(DropletUtils)
library(scuttle)
library(scater)
bcrank <- barcodeRanks(counts(sce)) #Rank cells by the number of UMIs

#Mitocondrial RNA
is.mito <- grep("mt-", rownames(sce)) #Rows marked as mitocndrial RNA
per.cell <- perCellQCMetrics(sce, subsets=list(Mito=is.mito)) #Computes many measures for understanding cell quality
#subsets_Mito_percent is a column of the object created above
high.mito <- isOutlier(per.cell$subsets_Mito_percent, type="higher") #Finds outliers
table(high.mito)

#Low expression
allzero <- rowMeans(counts(sce)==0)==1
sce <- sce[which(!allzero),]
sce
```
# *Normalization*
```{r}
library(scran)
cl <- quickCluster(sce) 
sce <- computeSumFactors(sce, clusters=cl) #Adds sizeFactor column to coldata
sce <- logNormCounts(sce) #Normalization + adds normalized counts in logcounts assay
logcounts(sce)[1:3 , 1:3]
```

# *Highly variable genes* + *Dimensionality Reduction*
```{r}
library(scuttle)
library(scater)
library(scran)
sce <- logNormCounts(sce)
dec <- modelGeneVar((sce))
topHVG <- getTopHVGs(dec, n = 1000)

#DIMENSIONALITY REDUCTIONÃ¹

#PCA
sce <-runPCA(sce, subset_row = topHVG)
plotPCA(sce)
#TSNE
sce <-runTSNE(sce, subset_row = topHVG, perplexity = 10)
plotTSNE(sce)
#UMAP
sce <-runUMAP(sce, subset_row = topHVG, n_neighbors = 5)
plotUMAP(sce)
```

# *Doublets*
```{r}
library(scDblFinder)
scores <- computeDoubletDensity(sce) #Identifies the scores for the possible doublets, we'll have to compare what we find with this
sce$DoubletScore <- scores           #Adds to colData
dbl.calls <- doubletThresholding(data.frame(score=scores), method="griffiths", returnType="call") #Identifies the doublets comparing
sce$doublets <- factor(dbl.calls)    #adds the doublets to coldata

sce <- sce[, dbl.calls == "singlet"] #filter the columns to take only the ones not marked as doublets in coldata
```


# *Louvian Clustering*
```{r}
library(igraph)
g <- buildSNNGraph(sce, k=10, use.dimred = 'PCA') #Uses the PCA results to make a neightbor graph
clust <- igraph::cluster_louvain(g)
sce$Louvain <- factor(membership(clust))          #Adds to coldata
plotTSNE(sce, colour_by="Louvain")                #Plot the resulting clustering using colors for t-sne
```
# *ANNOTATION*
```{r}
load("ref.RData") #The data to use as reference with singleR is stored here
ref
```

#DOESNT WORK FROM HERE!!!!
```{r}
library(SingleR)
#does the predictions
pred <- SingleR(test=sce, ref=ref, labels=ref$cell_ontology_class, de.method = "wilcox", assay.type.ref = "counts", clusters = sce$Louvain )
plotScoreHeatmap(pred) #Plot the predictions

sce$singlercl <- factor(pred$labels[sce$Louvain])#Add the prediction to coldata
plotTSNE(sce, colour_by = "singlercl")  
```
















